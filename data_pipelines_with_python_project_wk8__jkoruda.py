# -*- coding: utf-8 -*-
"""Copy of Data Pipelines with Python Project WK8_ JKoruda.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1H663cK33FGlKPXf_gN_yB1xeCcRDJYcC
"""

# -*- coding: utf-8 -*-
"""
Project Assignment-Data Pipelines with Python Project WK8_ JKoruda.ipynb

"""

!pip install neo4j

# Import required libraries
from neo4j import GraphDatabase
import pandas as pd
from datetime import datetime
import logging
import psycopg2


# connection details
neo4j_uri = "neo4j+s://2cb50e06.databases.neo4j.io"
neo4j_user = "neo4j"
neo4j_password = "FzQR4PxP9BPxsQdZnVKLd5bYE9Bj5-4vq4pHwkz6zXU"

# query to extract data
neo4j_query = """
MATCH (c:Customer)-[:HAS_SUBSCRIPTION]->(s:Subscription)-[:USES]->(sr:Service)
RETURN c.customer_id, s.subscription_id, sr.service_id, s.start_date, s.end_date, s.price
"""

# function to extract data from Neo4j and return a Pandas DataFrame
def extract_data():
    # Connect to Neo4j
    driver = GraphDatabase.driver(neo4j_uri, auth=(neo4j_user, neo4j_password))

    # Define a Cypher query to retrieve the data
    query = """
    MATCH (c:Customer)-[s:SUBSCRIBES_TO]->(sv:Service)
    RETURN c.id AS customer_id, s.start_date AS start_date, s.end_date AS end_date, s.price AS price,
          sv.id AS service_id, sv.name AS service_name
    """

    # Execute the query and retrieve the data
    with driver.session(database= "neo4j") as session:
       results = session.run(query)
       data = [dict(row) for row in results]


    # Convert the data to a pandas DataFrame
    _dataFrame = pd.DataFrame(data)
    return _dataFrame

# function to transform data
def transform_data(_dataFrame):
    # Convert start_date and end_date columns to datetime format
    transform_data(_dataFrame)['start_date'] = pd.to_datetime(transform_data(_dataFrame)['start_date'])
    transform_data(_dataFrame)['end_date'] = pd.to_datetime(transform_data(_dataFrame)['end_date'])
  
    
    # Remove rows where start_date or end_date is NaT
    _dataFrame = _dataFrame.dropna(subset=['start_date', 'end_date'], how='any')

    #drop all NaN values
    _dataFrame.dropna(inplace=True)

    # Create a new column for the duration of the service in days
    _dataFrame['duration_days'] = (_dataFrame['end_date'] - _dataFrame['start_date']).dt.days
    
    return _dataFrame

# Define function to load data into Postgres

def load_data(_dataFrame):
    try:
        conn = psycopg2.connect(
            host = "34.170.193.146",
            database = "PostrNeo4jProj",
            user = "postgres",
            password = "postres_1"
        )
        cursor = conn.cursor()

        # create table if it doesn't exist
        cursor.execute('''CREATE TABLE IF NOT EXISTS cust_service (
                            customer_id TEXT,
                            start_date DATE,
                            end_date DATE,
                            price FLOAT,
                            service_id TEXT,
                            service_name TEXT,
                            duration_days INT
                        )''')

        # insert data into table
        for index, row in _dataFrame.iterrows():
            cursor.execute('''INSERT INTO cust_service (customer_id, start_date, end_date, price, service_id, service_name, duration_days)
                              VALUES (%s, %s, %s, %s, %s, %s, %s)''', (row['customer_id'], row['start_date'], row['end_date'], row['price'], row['service_id'], row['service_name'], row['duration_days']))
        cursor.close()
        conn.commit()
        conn.close()
        logging.info('Data loaded successfully.')
    except Exception as e:
        logging.error(f'Error while loading data: {e}')

# define main function
def main():
    # Extract data from Neo4j
    _dataFrame = extract_data()
    
    # Transform data using Pandas
    transformed__dataFrame = transform_data(_dataFrame)
   
    # Load data into Postgres
    load_data(transformed__dataFrame)

# Call main function
if __name__ == "__main__":
    main()